notes and code while following Karpathy's
[Neural Networks: Zero to Hero](https://karpathy.ai/zero-to-hero.html)

## 1 The spelled-out intro to neural networks and back propagation

2h25'video

### derivatives

nice to have: interactive document

### micrograd

lenimgrad
- [x] minimial value, init and echo
  - vs python: in nim you get a decent default repr and init
  - no need to use a class
- [x] add value
  - vs python: more natural operator definition `+` (and no need to attach to class, again)

  